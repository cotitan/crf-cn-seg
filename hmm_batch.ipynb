{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import utils\n",
    "import argparse\n",
    "import json\n",
    "import pickle as pkl\n",
    "import traceback\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, model_file='data/hmm_params_1.pkl', n_epochs=1, test=False, test_file='', train_file='data/train.bmes', vocab_file='data/vocab.json')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_file', type=str, default=\"data/hmm_params_1.pkl\")\n",
    "parser.add_argument('--test', action='store_true')\n",
    "parser.add_argument('--train_file', type=str, default=\"data/train.bmes\")\n",
    "parser.add_argument('--test_file', type=str, default=\"\")\n",
    "parser.add_argument('--vocab_file', type=str, default=\"data/vocab.json\")\n",
    "parser.add_argument('--n_epochs', type=int, default=1)\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "args = parser.parse_args([])\n",
    "print(args)\n",
    "\n",
    "# load vocab, tag2id\n",
    "if not os.path.exists(args.vocab_file):\n",
    "    utils.build_vocab(args.train_file, args.vocab_file)\n",
    "vocab, tag2id = json.load(open(args.vocab_file))\n",
    "rev_vocab = {v:k for k,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2928"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "import utils_hmm as utils\n",
    "from importlib import reload\n",
    "reload(utils)\n",
    "\n",
    "X, Y, mask = utils.load_data(args.train_file, vocab, tag2id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import utils\n",
    "X, Y = utils.load_data(args.train_file, vocab, tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20000.000000\n",
       "mean        13.219500\n",
       "std          9.714033\n",
       "min          0.000000\n",
       "25%          7.000000\n",
       "50%         12.000000\n",
       "75%         18.000000\n",
       "90%         25.000000\n",
       "95%         30.000000\n",
       "99%         44.000000\n",
       "max        165.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pcts = [0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "pd.Series(len(x) for x in X).describe(pcts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm import HMM\n",
    "from hmm_batch import HMM as HMM1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi:\n",
      "tensor([[0.4791],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5209]])\n",
      "A:\n",
      "tensor([[0.0000, 0.7008, 0.2992, 0.0000],\n",
      "        [0.0000, 0.1247, 0.8753, 0.0000],\n",
      "        [0.6694, 0.0000, 0.0000, 0.3306],\n",
      "        [0.5853, 0.0000, 0.0000, 0.4147]])\n",
      "log_pi:\n",
      "tensor([[-7.3588e-01],\n",
      "        [-1.0000e+03],\n",
      "        [-1.0000e+03],\n",
      "        [-6.5217e-01]])\n",
      "log_A:\n",
      "tensor([[-1.0000e+03, -3.5556e-01, -1.2066e+00, -1.0000e+03],\n",
      "        [-1.0000e+03, -2.0816e+00, -1.3322e-01, -1.0000e+03],\n",
      "        [-4.0139e-01, -1.0000e+03, -1.0000e+03, -1.1068e+00],\n",
      "        [-5.3569e-01, -1.0000e+03, -1.0000e+03, -8.8012e-01]])\n",
      "pi:\n",
      "tensor([[0.4791],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5209]])\n",
      "A:\n",
      "tensor([[0.0000, 0.7008, 0.2992, 0.0000],\n",
      "        [0.0000, 0.1247, 0.8753, 0.0000],\n",
      "        [0.6694, 0.0000, 0.0000, 0.3306],\n",
      "        [0.5853, 0.0000, 0.0000, 0.4147]])\n",
      "log_pi:\n",
      "tensor([[-7.3588e-01],\n",
      "        [-1.0000e+03],\n",
      "        [-1.0000e+03],\n",
      "        [-6.5217e-01]])\n",
      "log_A:\n",
      "tensor([[-1.0000e+03, -3.5556e-01, -1.2066e+00, -1.0000e+03],\n",
      "        [-1.0000e+03, -2.0816e+00, -1.3322e-01, -1.0000e+03],\n",
      "        [-4.0139e-01, -1.0000e+03, -1.0000e+03, -1.1068e+00],\n",
      "        [-5.3569e-01, -1.0000e+03, -1.0000e+03, -8.8012e-01]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(HMM(), HMM())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_ = HMM(vocab, tag2id, torch.device('cpu'))\n",
    "hmm_1 = HMM1(vocab, tag2id, torch.device('cpu'))\n",
    "hmm_, hmm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open('data/train.bmes')\n",
    "vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "# tag2id = {\"<pad>\": 0}\n",
    "# vocab = {\"<unk>\": 0}\n",
    "tag2id = {'B': 0, 'M': 1, 'E': 2, 'S': 3}\n",
    "\n",
    "from collections import defaultdict\n",
    "word_cnt = defaultdict(int)\n",
    "for _, line in enumerate(fin):\n",
    "    if line.strip() == \"\":\n",
    "        continue\n",
    "    ch, tag = line.strip().split()\n",
    "    word_cnt[ch] += 1\n",
    "    if tag not in tag2id:\n",
    "        tag2id[tag] = len(tag2id)\n",
    "        \n",
    "df_cnt = pd.DataFrame([[k,v] for k,v in word_cnt.items()], columns=['word', 'cnt'])\n",
    "df_cnt = df_cnt.sort_values(by='cnt', ascending=False).reset_index(drop=True)\n",
    "\n",
    "for _,row in df_cnt.query('cnt>10').iterrows():\n",
    "    vocab[row['word']] = len(vocab)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'，的。、国一在中人了'"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(df_cnt.head(50)['word'].values.tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2928"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((943, 2), 0.912892127232749)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnt.query('cnt>300').shape, df_cnt.query('cnt>300')['cnt'].sum() / df_cnt['cnt'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9964581526547703, 1819979)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnt.query('cnt>10')['cnt'].sum() / df_cnt['cnt'].sum(), df_cnt.query('cnt>10')['cnt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   -9.3063,   -18.0331,   -26.9254,   -36.9771],\n",
       "        [-1007.8899,   -20.6349,   -27.2941,   -35.5722],\n",
       "        [-1009.5573,   -19.6312,   -26.9258,   -35.1331],\n",
       "        [   -8.5306,   -18.8868,   -27.6497,   -36.4039]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(hmm_.forward_alg([1,2,3,4]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# x, mask = np.array([[1,2,3,4,5,6],[3,4,5,6,7,8]]), np.array([[1,1,1,1,1,0],[1,1,1,1,1,1]])\n",
    "x, mask = np.array([[1,2,3,4,5,6]]), np.array([[1,1,1,1,1,0]])\n",
    "alphas1 = hmm_1.forward_alg(x, mask)\n",
    "betas1 = hmm_1.backward_alg(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 594.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = []\n",
    "betas = []\n",
    "gammas = []\n",
    "xis = []\n",
    "\n",
    "for r,obs in tqdm(enumerate(x), total=len(x)):\n",
    "    L_obs = mask[r].sum()\n",
    "    alpha = hmm_.forward_alg(obs[:L_obs])\n",
    "    beta = hmm_.backward_alg(obs[:L_obs])\n",
    "\n",
    "    alphas.append(alpha)\n",
    "    betas.append(beta)\n",
    "\n",
    "    gamma = []\n",
    "    print('length:', L_obs)\n",
    "    for t in range(L_obs):\n",
    "        gamma.append(alpha[t] + beta[t] - torch.logsumexp(alpha[t] + beta[t], dim=0))\n",
    "        # print(\"gamma:\", alpha[t].shape, beta[t].shape, torch.logsumexp(alpha[t] + beta[t], dim=0).shape)\n",
    "    gammas.append(gamma)\n",
    "\n",
    "    xi = []\n",
    "    for t in range(L_obs-1):\n",
    "        xi_t = alpha[t] + hmm_.log_A + beta[t+1].T + hmm_.log_B[:,obs[t+1]].view(1,-1)\n",
    "        denom = torch.logsumexp(xi_t, dim=[0,1])\n",
    "        xi.append(xi_t - denom)\n",
    "    xis.append(xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 5]), torch.Size([1, 4, 6]))"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.cat([a for a in alpha], dim=1).unsqueeze(0) for alpha in alphas], dim=0).shape, alphas1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   -9.3063,   -18.0331,   -26.9254,   -36.9771,   -44.3788],\n",
       "        [-1007.8899,   -20.6349,   -27.2941,   -35.5722,   -44.6588],\n",
       "        [-1009.5573,   -19.6312,   -26.9258,   -35.1331,   -43.6110],\n",
       "        [   -8.5306,   -18.8868,   -27.6497,   -36.4039,   -43.9621]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.cat(alpha, dim=1).unsqueeze(0) for alpha in alphas], dim=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   -9.3063,   -18.0331,   -26.9254,   -36.9771,   -44.3788,   -44.3788],\n",
       "        [-1007.8899,   -20.6349,   -27.2941,   -35.5722,   -44.6588,   -44.6588],\n",
       "        [-1009.5573,   -19.6312,   -26.9258,   -35.1331,   -43.6110,   -43.6110],\n",
       "        [   -8.5306,   -18.8868,   -27.6497,   -36.4039,   -43.9621,   -43.9621]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 5]), torch.Size([1, 4, 6]))"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.cat([a for a in beta], dim=1).unsqueeze(0) for beta in betas], dim=0).shape, betas1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-34.8742, -25.5698, -16.4639,  -7.9045,   0.0000],\n",
       "         [-33.9336, -25.5679, -16.6523,  -7.9711,   0.0000],\n",
       "         [-34.4353, -24.6913, -17.6851,  -8.5908,   0.0000],\n",
       "         [-34.4111, -24.7810, -17.6356,  -8.4992,   0.0000]]),\n",
       " tensor([[-34.8742, -25.5698, -16.4639,  -7.9045,   0.0000,   0.0000],\n",
       "         [-33.9336, -25.5679, -16.6523,  -7.9711,   0.0000,   0.0000],\n",
       "         [-34.4353, -24.6913, -17.6851,  -8.5908,   0.0000,   0.0000],\n",
       "         [-34.4111, -24.7810, -17.6356,  -8.4992,   0.0000,   0.0000]]))"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.cat([a for a in beta], dim=1).unsqueeze(0) for beta in betas], dim=0)[0], betas1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check_gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4933e+00, -9.1563e-01, -7.0202e-01, -2.1943e+00, -1.6915e+00,\n",
       "         -1.6915e+00],\n",
       "        [-9.9914e+02, -3.5155e+00, -1.2591e+00, -8.5604e-01, -1.9715e+00,\n",
       "         -1.9715e+00],\n",
       "        [-1.0013e+03, -1.6352e+00, -1.9236e+00, -1.0366e+00, -9.2375e-01,\n",
       "         -9.2375e-01],\n",
       "        [-2.5443e-01, -9.8056e-01, -2.5980e+00, -2.2158e+00, -1.2748e+00,\n",
       "         -1.2748e+00]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammas1 = alphas1 + betas1\n",
    "gammas1 = gammas1 - torch.logsumexp(gammas1, dim=1, keepdim=True)\n",
    "gammas1[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4933e+00, -9.1563e-01, -7.0202e-01, -2.1943e+00, -1.6915e+00],\n",
       "         [-9.9914e+02, -3.5155e+00, -1.2591e+00, -8.5604e-01, -1.9715e+00],\n",
       "         [-1.0013e+03, -1.6352e+00, -1.9236e+00, -1.0366e+00, -9.2375e-01],\n",
       "         [-2.5443e-01, -9.8056e-01, -2.5980e+00, -2.2158e+00, -1.2748e+00]]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.cat(gamma, dim=1).unsqueeze(0) for gamma in gammas], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 5]), torch.Size([1, 4, 6]))"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.cat(gamma, dim=1).unsqueeze(0) for gamma in gammas], dim=0).shape, gammas1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check xis1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4, 4])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xis1 = alphas1[:,:,:-1].transpose(1,2).unsqueeze(3) + hmm_1.log_A[None,None] + betas1[:,:,1:].transpose(1,2).unsqueeze(2) + hmm_1.log_B[:,x[:,1:]].transpose(0,1).transpose(1,2).unsqueeze(2)\n",
    "xis1 = xis1 - torch.logsumexp(xis1, dim=[2,3], keepdim=True)\n",
    "xis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4, 4])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.cat([tmp1.unsqueeze(0) for tmp1 in tmp], dim=0).unsqueeze(0) for tmp in xis], dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0012e+03, -3.5155e+00, -1.6352e+00, -1.0009e+03],\n",
       "         [-1.9997e+03, -1.0038e+03, -9.9915e+02, -1.9995e+03],\n",
       "         [-1.0018e+03, -2.0034e+03, -2.0007e+03, -1.0022e+03],\n",
       "         [-9.1563e-01, -1.0024e+03, -9.9965e+02, -9.8056e-01]]),\n",
       " tensor([[-1.0012e+03, -3.5155e+00, -1.6352e+00, -1.0009e+03],\n",
       "         [-1.9997e+03, -1.0038e+03, -9.9915e+02, -1.9995e+03],\n",
       "         [-1.0018e+03, -2.0034e+03, -2.0007e+03, -1.0022e+03],\n",
       "         [-9.1563e-01, -1.0024e+03, -9.9965e+02, -9.8056e-01]]))"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.cat([tmp1.unsqueeze(0) for tmp1 in tmp], dim=0).unsqueeze(0) for tmp in xis[:1]], dim=0)[0][0], xis1[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 4, 4]), torch.Size([2, 5, 4, 4]))"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.cat([tmp1.unsqueeze(0) for tmp1 in tmp], dim=0).unsqueeze(0) for tmp in xis[:1]], dim=0).shape, xis1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check new_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2246, 0.0000, 0.0000, 0.7754]])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pi1 = torch.exp(gammas1[:,:,0]).mean(dim=0, keepdim=True)\n",
    "new_pi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2246],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.7754]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pi = torch.cat([torch.exp(g[0]) for g in gammas], dim=1).mean(dim=1, keepdim=True)\n",
    "new_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check newA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6242, 0.3758, 0.0000],\n",
       "        [0.0000, 0.1473, 0.8527, 0.0000],\n",
       "        [0.5760, 0.0000, 0.0000, 0.4240],\n",
       "        [0.5929, 0.0000, 0.0000, 0.4071]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_A = torch.zeros(hmm_.n_state, hmm_.n_state)#.to(device)\n",
    "new_A_denom = torch.zeros(hmm_.n_state, 1)# .to(device)\n",
    "for r,obs in enumerate(x):\n",
    "    L_obs = mask[r].sum()\n",
    "    for t in range(L_obs-1):\n",
    "        new_A += torch.exp(xis[r][t])\n",
    "        new_A_denom += torch.exp(gammas[r][t])\n",
    "new_A = new_A / new_A_denom\n",
    "new_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6242, 0.3758, 0.0000],\n",
       "        [0.0000, 0.1473, 0.8527, 0.0000],\n",
       "        [0.5760, 0.0000, 0.0000, 0.4240],\n",
       "        [0.5929, 0.0000, 0.0000, 0.4071]], dtype=torch.float64)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newA = (torch.exp(xis1) * mask[:,1:,None,None]).sum(dim=[0,1])\n",
    "newA_denom = (torch.exp(gammas1[:,:,:-1,None]).transpose(1,2) * mask[:,1:,None,None]).sum(dim=[0,1])\n",
    "newA = newA / newA_denom\n",
    "newA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 5, 1), torch.Size([1, 5, 4]))"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[:,1:,None].shape, gammas1[:,:,:-1].transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.5956, 0.6748, 0.0000],\n",
       "        [0.0000, 0.4236, 2.1212, 0.0000],\n",
       "        [1.3047, 0.0000, 0.0000, 0.6889],\n",
       "        [0.8553, 0.0000, 0.0000, 0.6152]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(xis1).sum(dim=[0,1]) / torch.exp(gammas1[:,:,:-1]).sum(dim=[0,2]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check new_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1586, 0.2826,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0339,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1784,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4806, 0.2325,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update emission matrix\n",
    "new_B = torch.zeros(hmm_.n_state, hmm_.n_vocab)#.to(device)\n",
    "new_B_denom = torch.zeros(hmm_.n_state, 1)#.to(device)\n",
    "for r,obs in enumerate(x):\n",
    "    indicator = torch.arange(hmm_.n_vocab).unsqueeze(0).expand(hmm_.n_state, -1)#.to(hmm.device)\n",
    "    L_obs = mask[r].sum()\n",
    "    for t in range(L_obs):\n",
    "        new_B += torch.exp(gammas[r][t]) * (indicator == obs[t]).float()\n",
    "        new_B_denom += torch.exp(gammas[r][t])\n",
    "new_B = new_B / new_B_denom\n",
    "new_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1404, 0.2501,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0292,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1308,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4096, 0.1982,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator = torch.LongTensor(x).unsqueeze(2) == torch.arange(hmm_1.n_vocab)\n",
    "newB = (indicator.unsqueeze(1) * torch.exp(gammas1).unsqueeze(3)).sum(dim=[0,2]) / torch.exp(gammas1).sum(dim=[0,2]).unsqueeze(1)\n",
    "newB\n",
    "# indicator = torch.arange(hmm_1.n_vocab).unsqueeze(0).expand(hmm_1.n_state, -1).float()#.to(device)\n",
    "# newB1 = torch.einsum('rtn,sn->sv', [torch.exp(gammas1.transpose(1,2)), (indicator == torch.LongTensor(x).unsqueeze(2).expand(-1, -1, hmm_.n_vocab).float())])\n",
    "# newB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 6]), (1, 6))"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammas1.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1586, 0.2826,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0339,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1784,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4806, 0.2325,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newB = torch.zeros(hmm_1.n_state, hmm_1.n_vocab)\n",
    "mask_tensor = torch.tensor(mask).unsqueeze(1)\n",
    "\n",
    "denom = (torch.exp(gammas1) * mask_tensor).sum(dim=[0,2]).unsqueeze(1)\n",
    "for k in range(hmm_1.n_vocab):\n",
    "    indicator = torch.LongTensor(x) == k # [bs, T]\n",
    "    newB[:,k] = (indicator.unsqueeze(1) * torch.exp(gammas1) * mask_tensor).sum(dim=[0,2])\n",
    "newB = newB / denom\n",
    "newB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 6, 4700])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(indicator.unsqueeze(1) * torch.exp(gammas1).unsqueeze(3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 4700])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(indicator * torch.exp(gammas1[:,i,:]).unsqueeze(2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best path: [0, 1, 1, 1, 0]\n",
      "Best path probability: 0.0024084480000000005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def viterbi_decode(observed_sequence, states, start_prob, transition_prob, emission_prob):\n",
    "    num_states = len(states)\n",
    "    T = len(observed_sequence)\n",
    "    \n",
    "    # Initialize Viterbi matrix and backpointer matrix\n",
    "    V = np.zeros((num_states, T))\n",
    "    V[:, 0] = start_prob * emission_prob[:, observed_sequence[0]]\n",
    "    backpointers = np.zeros((num_states, T), dtype=int)\n",
    "    \n",
    "    # Perform Viterbi algorithm\n",
    "    for t in range(1, T):\n",
    "        for s in range(num_states):\n",
    "            temp = V[:, t-1] * transition_prob[:, s] * emission_prob[s, observed_sequence[t]]\n",
    "            V[s, t] = np.max(temp)\n",
    "            backpointers[s, t] = np.argmax(temp)\n",
    "    \n",
    "    # Decode the most likely state sequence\n",
    "    best_path_prob = np.max(V[:, -1])\n",
    "    best_path = [np.argmax(V[:, -1])]\n",
    "    for t in range(T-1, 0, -1):\n",
    "        best_path.insert(0, backpointers[best_path[0], t])\n",
    "    \n",
    "    return best_path, best_path_prob\n",
    "# Example usage\n",
    "observed_sequence = [0, 1, 0, 1, 0]\n",
    "states = [0, 1]\n",
    "start_prob = np.array([0.5, 0.5])\n",
    "transition_prob = np.array([[0.6, 0.4],\n",
    "                            [0.3, 0.7]])\n",
    "emission_prob = np.array([[0.8, 0.2],\n",
    "                          [0.2, 0.8]])\n",
    "best_path, best_path_prob = viterbi_decode(observed_sequence, states, start_prob, transition_prob, emission_prob)\n",
    "print(\"Best path:\", best_path)\n",
    "print(\"Best path probability:\", best_path_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
